
	

参加目的
AWSを使用したサービスの最新事例等を学び、

概要
主にAWSが提供しているサービスをIoT や機械学習、
などの技術やソリューションのご紹介、
マイクロサービスやコンテナ、サーバレス等を活用した開発スタイルの進化

全体的に企業様の成功事例の話が多かった

お話内容
メルカリ
・新機能ImageSearch
　写真に近い商品をメルカリで探す
　この画像学習をS3に保存したデータをAmazonEKSCluster（）
　を用いてトレーニングを行う
  高い可用性、あんぜん
　
・AI出品
　出品する商品の画像から、商品のカテゴリやタイトルを決めることができる

パナソニック
・Viewreka
　映像をAI処理する独自のエッジデバイスを使用してカメラ内で画像解析ができる
　上記端末から送られてきた画像を使い、分析、可視化を行う　→　AWS　SageMaker
　SageMaker  機械学習のワークフロー（モデルの構築、トレーニング、予測）を全部動かせる
　TensorFlow、Apache MXNet、PyTorch、Chainer、Scikit-learn、SparkML、Horovod、Keras、Gluon 
　を自動的に構成して最適化します。
　一般的に使用される機械学習アルゴリズムが組み込まれ、拡張性、スピード、正確性が調整されています

所感
技術の話よりは、企業さんの使用事例に関しての話が多いため、クラウドサービス使用ノウハウを主に学べました。
しかし、De:CodeのMRみたいな真新しい技術の話がほとんどない。

コンテナ

参加目的
コンテナが通常の仮想技術とどう違うのかを学ぶ
AWSが提供しているコンテナサービスの特徴、どういう時に使うものか知りたい

https://seq-blog.com/2019/06/15/aws-summit-tokyo%EF%BC%93%E6%97%A5%E7%9B%AE%E3%81%AE%E6%84%9F%E6%83%B3/
https://dev.classmethod.jp/cloud/aws-summit-tokyo-2019-c3-01-container/
https://speakerdeck.com/masachaco/10fen-kuraideza-nili-jie-suru-kubernetestoeks?slide=58

概要
コード、ランタイム環境、ライブラリ等を一つにまとめて、コンテナとして扱えば、環境が違っても動かないってことはないよねという技術です

コンテナを実行するためのエンジンとしてDockerがある
Docker＝コンテナと言われるぐらい有名です。

特徴
アプリが依存するもの（コード、実行環境、ライブラリ等）をひとまとめにして可搬性を持たせる仕組み
仮想マシンと違い、実体は（環境隔離した）プロセスなので起動が早い

仮想マシンは ハイパーバイザ上に GuestOS、そのGuestOS上でアプリケーションが起動
コンテナは Docker Engine 上にアプリケーションが複数起動
コンテナ起動はプロセス処理の時間のみ。 だから 仮想マシンと比べて起動が早い。

しかし、Dockerを利用したワークフロー（コンテナイメージ作成→コンテナ実行）では、コマンド実行しないといけないため、
思っている以上に手作業
複数サーバに対するオペレーションはスコープ外

→コンテナオーケストレーション
代わりに、コンテナ実行を行ってくれるツール
Amazon ECSがある

クラウドでコンテナを本番環境利用するためのオーケストレーター
各種AWSサービスとの高度な連携を持つ
数億コンテナ、数百万EC2インスタンスを管理するスケーラビリティ
Windows、Linuxをサポート

感想
コンテナの概要や、実行までのフローなど理解することができました。
私自身「知ってはいるけど、触ったことがない」コンテナ初心者なので 
今後実際に手を動かしてみて、今日のセッションで説明されていたメリットを実感




